![Image description](https://github.com/yuchaojiang/BIOS635/blob/master/Title.png)

### Instructor

[Yuchao Jiang](https://yuchaojiang.github.io/), Assistant Professor, Department of Biostatistics, UNC Chapel Hill<br /> 
Office: 4115D McGavran-Greenberg Hall<br /> 
Phone:  919-843-3656<br /> 
Email:  yuchaoj@email.unc.edu (contact via slack is preferred)

### Course Information

* **Description**: This course is an introductory course to machine learning and statistical learning and is required for MPH students with Data Science concentration. While some technical details will be covered, emphasis will be made on understanding the models, intuitions, and strengths and weaknesses of the various approaches. The goal is to equip students with knowledge of existing tools for data analysis and to get students prepared for more advanced courses in machine learning. Programming language will be R – students will learn how to use the free and powerful software R in connection with each of the methods exposed in the class. For deep learning, Keras/TensorFlow in Python will be introduced if time permits.

* **[Course Slack](https://bios635.slack.com)**

* **[Syllabus](https://www.dropbox.com/s/o7bu8kg1lcv74tc/BIOS%20635_Intro%20Machine%20Learning_Syllabus_v1.pdf?dl=0)**

* **[Schedule](https://www.dropbox.com/s/qoran00l1pfm2qz/CourseSchedule.pdf?dl=0)**

* **Class Time & Location**: Tuesdays and Thursdays, 9:30am – 10:45am, 2301 McGavran-Greenberg Hall.

* **Office Hours**: Thursdays, 2:00pm – 3:00pm, 3102 McGavran-Greenberg Hall. Virtual office hours may be conducted via Zoom/Whereby.

* **Grader**: Emily Damone, edamone@live.unc.edu.

### Lecture Slides and R Markdowns

* **Lecture 1**: Introduction ([slides](https://www.dropbox.com/s/erbn3lwwlklwo1f/Lecture_1_Intro.pdf?dl=0))

* **Lecture 2**: Curse of Dimensionality & Assessing Model Accuracy ([slides](https://www.dropbox.com/s/xvfnghxxyvo29r9/Lecture_2_curse_of_dimensionality_model_assessment.pdf?dl=0))

* **Lecture 3**: Bias-Variance Tradeoff & K-Nearest Neighbor ([slides](https://www.dropbox.com/s/b18vww2jryeqzvd/Lecture_3_knn_bias_variance.pdf?dl=0), [html](https://www.dropbox.com/s/b2ief97dq8pgp6s/KNN.html?dl=0))

* **Lecture 4**: Linear Regression ([slides](https://www.dropbox.com/s/kvbxaxijkx6li39/Lecture_4_linear_regression.pdf?dl=0), [html](https://www.dropbox.com/s/r0qgml0d2ccs0kp/Linear_Regression.html?dl=0))

* **Lecture 5**: Logistic Regression ([slides](https://www.dropbox.com/s/03rlp16nxcla9dc/Lecture_5_logistic_regression.pdf?dl=0), [html](https://www.dropbox.com/s/y9dy3q0dk8fc4i6/Logistic_Regression.html?dl=0))

* **Lecture 6**: Linear/Quadratic Discriminant Analysis ([slides](https://www.dropbox.com/s/t5588cr489wbmna/Lecture_6_LDA_QDA.pdf?dl=0), [html](https://www.dropbox.com/s/23jhtilj995ncjt/Discriminant_Analysis.html?dl=0))

* **Lecture 7**: Naive Bayes ([slides](https://www.dropbox.com/s/xblwqsd2gx5m89u/Lecture_7_Naive_Bayes.pdf?dl=0), [html](https://www.dropbox.com/s/52a4kenmzb8q7p9/Discriminant_Analysis_Naive_Bayes.html?dl=0))

* **Lecture 8**: Nonlinearity: Polynomial Regression, Spline & Generalized Additive Model ([slides](https://www.dropbox.com/s/qv0agbhjwr7wjhk/Lecture_8_Nonlinearity_Polynomial_Splines.pdf?dl=0), [html](https://www.dropbox.com/s/p205xa6gf7ekzlq/Nonlinearity.html?dl=0))

* **Lecture 9**: Cross-Validation ([slides](https://www.dropbox.com/s/nqb8pn78g816gxz/Lecture_9_Cross_Validation.pdf?dl=0), [html](https://www.dropbox.com/s/19uka0k3esit5c5/Cross_Validation.html?dl=0))

* **Lecture 10**: Bootstrap ([slides](https://www.dropbox.com/s/qi3xfy7chz5ecyh/Lecture_10_Bootstrap.pdf?dl=0), [html](https://www.dropbox.com/s/az716rnneaqstww/Bootstrap.html?dl=0))

* **Lecture 11**: Subset/Stepwise Selection, AIC, BIC & Adjusted R-Squared ([slides](https://www.dropbox.com/s/7jl5b11froj32ub/Lecture_11_Foward_Backward_Stepwise_Selection.pdf?dl=0), [html](https://www.dropbox.com/s/hdjpsmske6xhh5o/Stepwise_Selection.html?dl=0))

* **Lecture 12**: Shrinkage Methods, Ridge and Lasso Regression ([slides](https://www.dropbox.com/s/6wvzif6js0m8mcg/Lecture_12_Ridge_Lasso_Regression.pdf?dl=0), [html](https://www.dropbox.com/s/cd38i8itm6fnt3x/Ridge_Lasso.html?dl=0))

* **Lecture 13**: Principal Component Regression & Partial Least Squares ([slides](https://www.dropbox.com/s/zcnzue0meya4n9l/Lecture_13_Principal_Component_Analysis_Regression.pdf?dl=0), [html](https://www.dropbox.com/s/z4omrh5fs8c7vnf/PCA_PCR.html?dl=0))

* **Lecture 14**: Decision Trees ([slides](https://www.dropbox.com/s/fq4a32v920e6804/Lecture_14_Decision_Trees.pdf?dl=0), [html](https://www.dropbox.com/s/h3m4n0gpv9yndhz/Decision_Trees.html?dl=0))

* **Lecture 15**: Bagging, Boosting & Random Forest ([slides](https://www.dropbox.com/s/6od0gshjxbzczpv/Lecture_15_Bagging_Boosting_Random_Forest.pdf?dl=0), [html](https://www.dropbox.com/s/t1ulv0fd7jayp1n/Bagging_Boosting_Random_Forest.html?dl=0))

* **Lecture 16**: Midterm Review ([slides](https://www.dropbox.com/s/a6z8lbxn1ix52er/Lecture_16_Midterm_Review.pdf?dl=0))

* **Lecture 17**: Support Vector Classifier & Kernel Methods ([slides](https://www.dropbox.com/s/wmjx7ajeknk8wnz/Lecture_16_Support_Vector_Classifiers_Kernel.pdf?dl=0), [html](https://www.dropbox.com/s/lerkxnz1psd1jcn/Support_Vector_Classifier.html?dl=0))

* **Lecture 18**: Support Vector Machine ([slides](https://www.dropbox.com/s/5is9iulgph3xd7l/Lecture_17_Support_Vector_Machine.pdf?dl=0), [html](https://www.dropbox.com/s/a7rfzucb857c3i9/SVM.html?dl=0))

* **Lecture 19**: Unsupervised Learning (Dimension Reduction) ([slides](https://www.dropbox.com/s/4f5rhbbu9w2wczj/Lecture_18_dimension_reduction.pdf?dl=0), [html](https://www.dropbox.com/s/gshykuhjypz7268/dim_reduction.html?dl=0))

* **Lecture 20**: K-Means Clustering & Hierarchical Clustering ([slides](https://www.dropbox.com/s/wv1gjsxjldrh4e0/Lecture_19_k_means_hierarchical_clustering.pdf?dl=0), [html](https://www.dropbox.com/s/6aijrx2eahgc1go/kmeans_hierarchical.html?dl=0))

* **Lecture 21**: Gaussian Mixture Model & EM Algorithm ([slides](https://www.dropbox.com/s/jo6iinv8ryf139r/Lecture_20_Gaussian_Mixture_EM.pdf?dl=0), [html](https://www.dropbox.com/s/sujzhws4zxkx3vi/GMM.html?dl=0))

* **Lecture 22**: Overview of Classification Algorithms & Project Guidelines ([slides](https://www.dropbox.com/s/xer1rrov1c4e9uh/Lecture_21_Practical_Guidelines_Project.pdf?dl=0))

* **Lecture 23**: Gradient Descent & Forward/Backward Propagation ([slides](https://www.dropbox.com/s/mpubkndjpyy1ef4/Lecture_23_Forward_Backward_Propagation.pdf?dl=0))

* **Lecture 24**: Deep Neural Network ([slides](https://www.dropbox.com/s/nv4pefcbam1nd8u/Lecture_24_Deep_Neural_Network_Big_Data.pdf?dl=0))

### Assignments

* **Assignment 1** ([rmd](https://www.dropbox.com/s/yd9w13iu2d7bzc6/Assignment1.rmd?dl=0), [data](https://www.dropbox.com/s/ql5chsraaa2nkwn/data.zip?dl=0), [solutions](https://www.dropbox.com/s/xxk5l3zq3q45kn2/Assignment1_Solutions.html?dl=0))

* **Assignment 2** ([rmd](https://www.dropbox.com/s/prgksbhtcgsad6w/Assignment2.rmd?dl=0), [solutions](https://www.dropbox.com/s/p90bfmna7k9giss/Assignment2_Solutions.html?dl=0))

* **Assignment 3** ([rmd](https://www.dropbox.com/s/cb6ubr2ukjbxxyd/Assignment3.rmd?dl=0), [solutions](https://www.dropbox.com/s/r00hmlq6mtzoamw/Assignment3_solutions.html?dl=0))

* **Assignment 4** ([rmd](https://www.dropbox.com/s/w12hfv3x1z1pfyq/Assignment4.rmd?dl=0), [solutions](https://www.dropbox.com/s/hneuxmm47lyq9h1/Assignment4_solutions.html?dl=0))

### Projects

* **Project 1**: [Predict the Effect of Genetic Variants to Enable Personalized Medicine](https://www.kaggle.com/c/msk-redefining-cancer-treatment/)

* **Project 2**: [West Nile Virus Prediction](https://www.kaggle.com/c/predict-west-nile-virus/)

* **Project 3**: [Predict Parkinson’s Disease Progression with Smartphone Data](https://www.kaggle.com/c/predicting-parkinson-s-disease-progression-with-smartphone-data)

### Exams

* **Midterm** ([exam](https://www.dropbox.com/s/pywi8c8vluk20v0/midterm.pdf?dl=0), [solutions](https://www.dropbox.com/s/koaylbmicgozhqu/midterm_solutions.pdf?dl=0))

* **Final** (waived due to COVID-19)

### Other Resources

* **Machine Learning Textbooks**:<br />
  * Bishop, [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), Springer (more advanced)
  * Efron and Hastie, [Computer Age Statistical Inference](https://web.stanford.edu/~hastie/CASI/), Cambridge University Press (recommended)
  * Goodfellow, Bengio, and Courville, [Deep Learning](https://www.deeplearningbook.org/), MIT Press (more advanced)
  * Hastie, Tibshirani, Friedman, [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/), Springer (more advanced)
  * James, Witten, Hastie, and Tibshirani, [An Introduction to Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/ISL/), Springer (**required**)
  * Murphy, [Machine Learning: A Probabilistic Perspective](https://www.cs.ubc.ca/~murphyk/MLbook/), MIT Press (more advanced)

* **Other Machine Learning Resources**:<br />
  * [Introduction to Data Science: Data Analysis and Prediction Algorithms in R](https://rafalab.github.io/dsbook/) by Rafael Irizarry
  * [Machine Learning Lecture Notes](http://cs229.stanford.edu/syllabus.html) by Andrew Ng
  * [R for Data Science](https://r4ds.had.co.nz/) by Garrett Grolemund and Hadley Wickham
  * [Statistical Learning MOOC](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/) by Trevor Hastie and Rob Tibshirani

* **[Tips for Presentation](https://www.dropbox.com/s/k5ymqz8qflpeskl/Tips_for_presentations.pdf?dl=0)**
